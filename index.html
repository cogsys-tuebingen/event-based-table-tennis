<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="An Event-Based Perception Pipeline for a Table Tennis Robot">
  <meta name="keywords" content="Table Tennis Robot, Event Camera, Event-Based Computer Vision, Object Detection">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>An Event-Based Perception Pipeline for a Table Tennis Robot</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Nerfies: Deformable Neural Radiance Fields</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://andreasaziegler.github.io/">Andreas Ziegler</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://uni-tuebingen.de/de/226101">Thomas Gossard</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://arrenglover.github.io/">Arren Glover</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://uni-tuebingen.de/de/138703">Andreas Zell</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of TÃ¼bingen,</span>
            <span class="author-block"><sup>2</sup>Istituto Italiano Tecnologia</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block"> -->
              <!--   <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA" -->
              <!--      class="external-link button is-normal is-rounded is-dark"> -->
              <!--     <span class="icon"> -->
              <!--         <i class="fab fa-youtube"></i> -->
              <!--     </span> -->
              <!--     <span>Video</span> -->
              <!--   </a> -->
              <!-- </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <center>
        <img class="round" style="width:600px" src="./static/images/teaser.png" />
      </center>
      <!-- <video id="teaser" autoplay muted loop playsinline height="100%"> -->
      <!--   <source src="./static/videos/teaser.mp4" -->
      <!--           type="video/mp4"> -->
      <!-- </video> -->
      <h2 class="subtitle has-text-centered">
        Background: The industrial robot arm of our table tennis robot setup for which the proposed perception pipeline is designed. The two event-based cameras, indicated with <font color="orange">orange circles</font>, are mounted on the ceiling. Foreground: The event streams of the two event-based cameras with detected balls on the EROS event surface, visualized <font color="green">in green</font>, the triangulation process, indicated in violet, and the triangulated 3D trajectory, shown <font color="blue">in blue</font>.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Table tennis robots gained traction over the last years and have become a popular research challenge for control and perception algorithms. Fast and accurate ball detection is crucial for enabling a robotic arm to rally the ball back successfully. So far, most table tennis robots use conventional, frame-based cameras for the perception pipeline. While frame-based cameras have great advantages, they do suffer from motion blur if the frame rate is not high enough for fast-moving objects. Event-based cameras, on the other hand, do not suffer from this limitation since pixels report changes in intensity asynchronously and independently, leading to an event stream with a temporal resolution in &micro;s. To the best of our knowledge, we present the first real-time perception pipeline for a table tennis robot that uses only event-based cameras. We show that compared to a frame-based pipeline, event-based perception pipelines give an order of magnitude more position estimates of the ball, which is beneficial for the estimation and prediction of the ball's position, velocity, and spin, resulting in lower errors and uncertainties. This is an advantage for the robot control, which has to be fast, given the short time a table tennis ball is flying until the robot has to hit back.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered"> -->
    <!--   <div class="column is-four-fifths"> -->
    <!--     <h2 class="title is-3">Video</h2> -->
    <!--     <div class="publication-video"> -->
    <!--       <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0" -->
    <!--               frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
    <!--     </div> -->
    <!--   </div> -->
    <!-- </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{ziegler2025arXiv,
  author    = {Ziegler, Andreas and Gossard, Thomas and Glover, Arren and Zell, Andreas},
  title     = {An Event-Based Perception Pipeline for a Table Tennis Robot},
  journal   = {arXiv},
  year      = {2025},
}</code></pre>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Acknowledgements. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Acknowledgements</h2>
        <div class="content has-text-justified">
          <p>
            Special thanks to <a href="https://ai.sony/">Sony AI</a> for partially funding this project. We would also like to thank Mario Laux for his help with the C++ implementation of the ball detector. Thanks to Bernd Pfrommer for his open source contributions to many (event-based vision) ROS packages, two of them used in this work.
          </p>
        </div>
      </div>
    </div>
    <!--/ Acknowledgements. -->
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website borrowed from the <a
              href="https://github.com/nerfies/nerfies.github.io"><span class="dnerf">Nerfies</span></a>.
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
